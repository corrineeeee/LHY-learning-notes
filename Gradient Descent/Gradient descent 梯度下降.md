# Gradient descent æ¢¯åº¦ä¸‹é™

**æ¢¯åº¦ä¸‹é™æ³•æ˜¯ä¸æ–­å»æ›´æ–°å‚æ•°xä»¥æ‰¾åˆ°è§£çš„æ–¹æ³•**

ä¸€ç¶­åº¦çš„ç´”é‡**x**çš„æ¢¯åº¦å°±æ˜¯ç®—**f(x)**å°**x**çš„å¾®åˆ†(å°±æ˜¯åªæœ‰ä¸€ä¸ªx

å¤šç¶­åº¦çš„å‘é‡**x**çš„æ¢¯åº¦å°±æ˜¯ç®—**f(x)**å°**x**æ‰€æœ‰å…ƒç´ çš„åå¾®åˆ† (æœ‰x1,x2...xn

<img src=".\img\2.jpg" style="zoom:50%;" />

â€‹	æ‰€ä»¥è¦å…ˆéš¨æ©Ÿç”¢ç”Ÿä¸€çµ„åˆå§‹åƒæ•¸çš„ã€Œè§£ã€ï¼Œç„¶å¾Œæ ¹æ“šé€™çµ„éš¨æ©Ÿç”¢ç”Ÿçš„ã€Œè§£ã€é–‹å§‹ç®—æ­¤ã€Œè§£ã€çš„æ¢¯åº¦æ–¹å‘å¤§å°ï¼Œç„¶å¾Œå°‡é€™å€‹ã€Œè§£ã€å»æ¸›å»æ¢¯åº¦æ–¹å‘å¤§å°ï¼Œå¾—åˆ°çš„ã€Œè§£ã€å°±æ˜¯ä¸‹ä¸€è½®è¿­ä»£çš„åˆå§‹ã€Œè§£ã€

![](.\img\1.jpg)

-  tæ˜¯ç¬¬å¹¾æ¬¡æ›´æ–°åƒæ•¸ (è¿­ä»£æ¬¡æ•°

-  Î³æ˜¯å­¸ç¿’ç‡(Learning rate)  

  â€‹									å…¶å®å°±æ˜¯ä¼šå˜æˆ<img src=".\img\3.jpg" style="zoom: 67%;" />

### ä¸€äº›å…³äºgradient descentçš„tip

- #### è°ƒlearning rate

  **Adagrad**

  æ ¹æ®updateçš„gradientå€¼æ¥update learning rate

  

  <img src=".\img\4.jpg" style="zoom:80%;" />

  -  ğœ ğ‘¡ : root mean square of the previous derivatives of parameter w 

    è¿‡å»æ‰€æœ‰å‚æ•°updateçš„ç»“æœçš„å‡æ–¹æ ¹

- ###  Stochastic Gradient Descent 

- ###   Feature Scaling 

   Make different features have the same scaling 